{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Deep Q-Learning \n",
    "\n",
    "The goal of this assignment is to implement and experiment with both single-core and distributed versions of the deep reinforcement learning algorithm Deep Q Networks (DQN). In particular, DQN will be run in the classic RL benchmark Cart-Pole and abblation experiments will be run to observe the impact of the different DQN components. \n",
    "\n",
    "The relevant content about DQN can be found Q-Learning and SARSA are in the following course notes from CS533.\n",
    "\n",
    "https://oregonstate.instructure.com/courses/1719746/files/75047394/download?wrap=1\n",
    "\n",
    "The full pseudo-code for DQN is on slide 45 with prior slides introducing the individual components. \n",
    "\n",
    "\n",
    "## Recap of DQN \n",
    "\n",
    "From the course slides it can be seen that DQN is simply the standard table-based Q-learning algorithm but with three extensions:\n",
    "\n",
    "1) Use of function approximation via a neural network instead of a Q-table. \n",
    "2) Use of experience replay. \n",
    "3) Use of a target network. \n",
    "\n",
    "Extension (1) allows for scaling to problems with enormous state spaces, such as when the states correspond to images or sequences of images. Extensions (2) and (3) are claimed to improve the robustness and effectiveness of DQN compared. \n",
    "\n",
    "(2) adjusts Q-learning so that updates are not just performed on individual experiences as they arrive. But rather, experiences are stored in a memory buffer and updates are performed by sampling random mini-batches of experience tuples from the memory buffer and updating the network based on the mini-batch. This allows for reuse of experience as well as helping to reduce correlation between successive updates, which is claimed to be beneficial. \n",
    "\n",
    "(3) adjusts the way that target values are computed for the Q-learning updates. Let $Q_{\\theta}(s,a)$ be the function approximation network with parameters $\\theta$ for representing the Q-function. Given an experience tuple $(s, a, r, s')$ the origional Q-learning algorithm updates the parameters so that $Q_{\\theta}(s,a)$ moves closer to the target value: \n",
    "\\begin{equation}\n",
    "r + \\beta \\max_a' Q_{\\theta}(s',a') \n",
    "\\end{equation}\n",
    "Rather, DQN stores two function approximation networks. The first is the update network with parameters $\\theta$, which is the network that is continually updated during learning. The second is a target network with parameters $\\theta'$. Given the same experience tuple, DQN will update the parameters $\\theta$ so that $Q_{\\theta}(s,a)$ moves toward a target value based on the target network:\n",
    "\\begin{equation}\n",
    "r + \\beta \\max_a' Q_{\\theta'}(s',a') \n",
    "\\end{equation}\n",
    "Periodically the target network is updated with the most recent parameters $\\theta' \\leftarrow \\theta$. This use of a target network is claimed to stabilize learning.\n",
    "\n",
    "In the assignment you will get to see an example of the impact of both the target network and experience replay.\n",
    "\n",
    "Further reading about DQN and its application to learning to play Atari games can be found in the following paper. \n",
    "\n",
    "Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Riedmiller, M., Fidjeland, A.K., Ostrovski, G. and Petersen, S., 2015. Human-level control through deep reinforcement learning. Nature, 518(7540), p.529.\n",
    "https://oregonstate.instructure.com/courses/1719746/files/75234294/download?wrap=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --user gym[Box2D]\n",
    "# !pip3 install --user torch\n",
    "# !pip3 install --user JSAnimation\n",
    "# !pip3 install --user matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the packages for enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "import ray\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from random import uniform, randint\n",
    "\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "from dqn_model import DQNModel\n",
    "from dqn_model import _DQNModel\n",
    "from memory import ReplayBuffer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "FloatTensor = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful PyTorch functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "This assignment will use the PyTorch library for the required neural network functionality. You do not need to be familiar with the details of PyTorch or neural network training. However, the assignment will require dealing with data in the form of tensors.  \n",
    "\n",
    "The mini-batches used to train the PyTorch neural network is expected to be represented as a tensor matrix. The function `FloatTensor` can convert a list or NumPy matrix into a tensor matrix if needed. \n",
    "\n",
    "You can find more infomation here: https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 2, 1], [6, 4, 5], [7, 8, 9]]\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[3., 2., 1.],\n",
      "        [6., 4., 5.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# list\n",
    "m = [[3,2,1],[6,4,5],[7,8,9]]\n",
    "print(m)\n",
    "\n",
    "# tensor matrix\n",
    "m_tensor = FloatTensor(m)\n",
    "print(type(m_tensor))\n",
    "print(m_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor.max()\n",
    "Once you have a tenosr maxtrix, you can use torch.max(m_tensor, dim) to get the max value and max index corresponding to the dimension you choose.\n",
    "```\n",
    ">>> a = torch.randn(4, 4)\n",
    ">>> a\n",
    "tensor([[-1.2360, -0.2942, -0.1222,  0.8475],\n",
    "        [ 1.1949, -1.1127, -2.2379, -0.6702],\n",
    "        [ 1.5717, -0.9207,  0.1297, -1.8768],\n",
    "        [-0.6172,  1.0036, -0.6060, -0.2432]])\n",
    ">>> torch.max(a, 1)\n",
    "torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1]))\n",
    "```\n",
    "You can find more infomation here: https://pytorch.org/docs/stable/torch.html#torch.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 6., 9.]) tensor([0, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "max_value, index = torch.max(m_tensor, dim = 1)\n",
    "print(max_value, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment\n",
    "### CartPole-v0:  \n",
    "CartPole is a classic control task that is often used as an introductory reinforcement learning benchmark. The environment involves controlling a 2d cart that can move in either the left or right direction on a frictionless track. A pole is attached to the cart via an unactuated joint. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.  \n",
    "(You can find more infomation by this Link: https://gym.openai.com/envs/CartPole-v0/)  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Env name and action space for CartPole\n",
    "ENV_NAME = 'CartPole-v0'\n",
    "# Move left, Move right\n",
    "ACTION_DICT = {\n",
    "    \"LEFT\": 0,\n",
    "    \"RIGHT\":1\n",
    "}\n",
    "# Register the environment\n",
    "env_CartPole = gym.make(ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set result saveing floder\n",
    "result_floder = ENV_NAME\n",
    "result_file = ENV_NAME + \"/results.txt\"\n",
    "if not os.path.isdir(result_floder):\n",
    "    os.mkdir(result_floder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function\n",
    "Plot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(total_rewards ,learning_num, legend):\n",
    "    print(\"\\nLearning Performance:\\n\")\n",
    "    episodes = []\n",
    "    for i in range(len(total_rewards)):\n",
    "        episodes.append(i * learning_num + 1)\n",
    "        \n",
    "    plt.figure(num = 1)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(episodes, total_rewards)\n",
    "    plt.title('performance')\n",
    "    plt.legend(legend)\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.ylabel(\"total rewards\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams\n",
    "When function approximation is involves, especially neural networks, additional hyper parameters are inroduced and setting the parameters can require experience. Below is a list of the hyperparameters used in this assignment and values for the parameters that have worked well for a basic DQN implementation. You will adjust these values for particular parts of the assignment. For example, experiments that do not use the target network will set 'use_target_model' to False. \n",
    "\n",
    "You can find the more infomation about these hyperparameters in the notation of DQN_agent.init() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_CartPole = {\n",
    "    'epsilon_decay_steps' : 100000, \n",
    "    'final_epsilon' : 0.1,\n",
    "    'batch_size' : 32, \n",
    "    'update_steps' : 10, \n",
    "    'memory_size' : 2000, \n",
    "    'beta' : 0.99, \n",
    "    'model_replace_freq' : 2000,\n",
    "    'learning_rate' : 0.0003,\n",
    "    'use_target_model': True\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 1: Non-distributed DQN\n",
    "\n",
    "In this part, you will complete an implementation of DQN and run experiments on the CartPole environment from OpenAI Gym.  \n",
    "Note that OpenAI Gym has many other environments that use the same interface---so this experience will allow the curious student to easily explore these algorithms more widely. \n",
    "\n",
    "Below you need to fill in the missing code for the DQN implementation. \n",
    "\n",
    "The Run function below can then be used to generate learning curves. \n",
    "\n",
    "You should conduct the following experiments involving different features of DQN. \n",
    "\n",
    "1. DQN without a replay buffer and without a target network. This is just standard Q-learning with a function approximator.\n",
    "    The corresponding parameters are: memory_size = 1, update_steps = 1, batch_size = 1, use_target_model = False  \n",
    "    \n",
    "2. DQN without a replay buffer (but including the target network).   \n",
    "    The corresponding parameters are: memory_size = 1, update_steps = 1, batch_size = 1, use_target_model = True  \n",
    "\n",
    "3. DQN with a replay buffer, but without a target network.   \n",
    "    Here you set use_target_model = False and otherwise set the replay memory parameters to the above suggested values \n",
    "   \n",
    "4. Full DQN\n",
    "\n",
    "For each experiment, record the parameters that you used, plot the resulting learning curves, and give a summary of your observations regarding the differences you observed. \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DQN Agent\n",
    "\n",
    "The full DQN agent involves a number of functions, the neural network, and the replay memory. Interfaces to a neural network model and memory are provided. \n",
    "\n",
    "Some useful information is below:   \n",
    "- Neural Network Model: The network is used to represent the Q-function $Q(s,a)$. It takes a state $s$ as input and returns a vector of Q-values, one value for each action. The following interface functions are used for predicting Q-values, actions, and updating the neural network model parameters. \n",
    "    1. Model.predict(state) --- Returns the action that has the best Q-value in 'state'.\n",
    "    2. Model.predict_batch(states) --- This is used to predict both the Q-values and best actions for a batch of states. Given a batch of states, the function returns: 1) 'best_actions' a vector containing the best action for each input state, and 2) 'q_values' a matrix where each row gives the Q-value for all actions of each state (one row per state).   \n",
    "    3. Model.fit(q_values, q_target) --- It is used to update the neural network (via back-propagation). 'q_values' is a vector containing the Q-value predictions for a list of state-action pairs (e.g. from a batch of experience tuples). 'q_target' is a vector containing target values that we would like the correspoinding predictions to get closer to. This function updates the network in a way that the network predictions will ideally be closer to the targets. There is no return value.  \n",
    "    4. Model.replace(another_model) --- It takes another model as input, and replace the weight of itself by the input model.\n",
    "- Memory: This is the buffer used to store experience tuples for experience replay.\n",
    "    1. Memory.add(state, action, reward, state', is_terminal) --- It takes one example as input, and store it into its storage.  \n",
    "    2. Memory.sample(batch_size) --- It takes a batch_size int number as input. Return 'batch_size' number of randomly selected examples from the current memory buffer. The batch takes the form (states, actions, rewards, states', is_terminals) with each component being a vector/list of size equal to batch_size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_agent(object):\n",
    "    def __init__(self, env, hyper_params, action_space = len(ACTION_DICT)):\n",
    "        \n",
    "        self.env = env\n",
    "        self.max_episode_steps = env._max_episode_steps\n",
    "        \n",
    "        \"\"\"\n",
    "            beta: The discounted factor of Q-value function\n",
    "            (epsilon): The explore or exploit policy epsilon. \n",
    "            initial_epsilon: When the 'steps' is 0, the epsilon is initial_epsilon, 1\n",
    "            final_epsilon: After the number of 'steps' reach 'epsilon_decay_steps', \n",
    "                The epsilon set to the 'final_epsilon' determinately.\n",
    "            epsilon_decay_steps: The epsilon will decrease linearly along with the steps from 0 to 'epsilon_decay_steps'.\n",
    "        \"\"\"\n",
    "        self.beta = hyper_params['beta']\n",
    "        self.initial_epsilon = 1\n",
    "        self.final_epsilon = hyper_params['final_epsilon']\n",
    "        self.epsilon_decay_steps = hyper_params['epsilon_decay_steps']\n",
    "\n",
    "        \"\"\"\n",
    "            episode: Record training episode\n",
    "            steps: Add 1 when predicting an action\n",
    "            learning: The trigger of agent learning. It is on while training agent. It is off while testing agent.\n",
    "            action_space: The action space of the current environment, e.g 2.\n",
    "        \"\"\"\n",
    "        self.episode = 0\n",
    "        self.steps = 0\n",
    "        self.best_reward = 0\n",
    "        self.learning = True\n",
    "        self.action_space = action_space\n",
    "\n",
    "        \"\"\"\n",
    "            input_len: The input length of the neural network. It equals to the length of the state vector.\n",
    "            output_len: The output length of the neural network. It is equal to the action space.\n",
    "            eval_model: The model for predicting action for the agent.\n",
    "            target_model: The model for calculating Q-value of next_state to update 'eval_model'.\n",
    "            use_target_model: Trigger for turn 'target_model' on/off\n",
    "        \"\"\"\n",
    "        state = env.reset()\n",
    "        input_len = len(state)\n",
    "        output_len = action_space\n",
    "        self.eval_model = DQNModel(input_len, output_len, learning_rate = hyper_params['learning_rate'])\n",
    "        self.use_target_model = hyper_params['use_target_model']\n",
    "        if self.use_target_model:\n",
    "            self.target_model = DQNModel(input_len, output_len)\n",
    "#         memory: Store and sample experience replay.\n",
    "        self.memory = ReplayBuffer(hyper_params['memory_size'])\n",
    "        \n",
    "        \"\"\"\n",
    "            batch_size: Mini batch size for training model.\n",
    "            update_steps: The frequence of traning model\n",
    "            model_replace_freq: The frequence of replacing 'target_model' by 'eval_model'\n",
    "        \"\"\"\n",
    "        self.batch_size = hyper_params['batch_size']\n",
    "        self.update_steps = hyper_params['update_steps']\n",
    "        self.model_replace_freq = hyper_params['model_replace_freq']\n",
    "        \n",
    "    # Linear decrease function for epsilon\n",
    "    def linear_decrease(self, initial_value, final_value, curr_steps, final_decay_steps):\n",
    "        decay_rate = curr_steps / final_decay_steps\n",
    "        if decay_rate > 1:\n",
    "            decay_rate = 1\n",
    "        return initial_value - (initial_value - final_value) * decay_rate\n",
    "    \n",
    "    def explore_or_exploit_policy(self, state):\n",
    "        p = uniform(0, 1)\n",
    "        # Get decreased epsilon\n",
    "        epsilon = self.linear_decrease(self.initial_epsilon, \n",
    "                               self.final_epsilon,\n",
    "                               self.steps,\n",
    "                               self.epsilon_decay_steps)\n",
    "        \n",
    "        if p < epsilon:\n",
    "            #return action\n",
    "            return randint(0, self.action_space - 1)\n",
    "        else:\n",
    "            #return action\n",
    "            return self.greedy_policy(state)\n",
    "        \n",
    "    def greedy_policy(self, state):\n",
    "        return self.eval_model.predict(state)\n",
    "    \n",
    "    # This next function will be called in the main RL loop to update the neural network model given a batch of experience\n",
    "    # 1) Sample a 'batch_size' batch of experiences from the memory.\n",
    "    # 2) Predict the Q-value from the 'eval_model' based on (states, actions)\n",
    "    # 3) Predict the Q-value from the 'target_model' base on (next_states), and take the max of each Q-value vector, Q_max\n",
    "    # 4) If is_terminal == 1, q_target = reward + discounted factor * Q_max, otherwise, q_target = reward\n",
    "    # 5) Call fit() to do the back-propagation for 'eval_model'.\n",
    "    def update_batch(self):\n",
    "        if len(self.memory) < self.batch_size or self.steps % self.update_steps != 0:\n",
    "            return\n",
    "\n",
    "        batch = self.memory.sample(self.batch_size)\n",
    "\n",
    "        (states, actions, reward, next_states,\n",
    "         is_terminal) = batch\n",
    "        \n",
    "        states = states\n",
    "        next_states = next_states\n",
    "        terminal = FloatTensor([0 if t else 1 for t in is_terminal])\n",
    "        reward = FloatTensor(reward)\n",
    "        batch_index = torch.arange(self.batch_size,\n",
    "                                   dtype=torch.long)\n",
    "        \n",
    "        # Current Q Values\n",
    "        _, q_values = self.eval_model.predict_batch(states)\n",
    "        q_values = q_values[batch_index, actions]\n",
    "        \n",
    "        # Calculate target\n",
    "        if self.use_target_model:\n",
    "            actions, q_next = self.target_model.predict_batch(next_states)\n",
    "        else:\n",
    "            actions, q_next = self.eval_model.predict_batch(next_states)\n",
    "            \n",
    "        #INSERT YOUR CODE HERE --- neet to compute 'q_targets' used below\n",
    "        q_target = reward + self.beta * torch.max(q_next, dim=1)[0] * terminal\n",
    "        \n",
    "        # update model\n",
    "        self.eval_model.fit(q_values, q_target)\n",
    "    \n",
    "    def learn_and_evaluate(self, training_episodes, test_interval):\n",
    "        test_number = training_episodes // test_interval\n",
    "        all_results = []\n",
    "        \n",
    "        for i in range(test_number):\n",
    "            # learn\n",
    "            self.learn(test_interval)\n",
    "            \n",
    "            # evaluate\n",
    "            avg_reward = self.evaluate(i)\n",
    "            all_results.append(avg_reward)\n",
    "            \n",
    "        return all_results\n",
    "    \n",
    "    def learn(self, test_interval):\n",
    "        for episode in tqdm(range(test_interval), desc=\"Training\"):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            steps = 0\n",
    "            \n",
    "            while steps < self.max_episode_steps and not done:\n",
    "                #INSERT YOUR CODE HERE\n",
    "                steps += 1\n",
    "                self.steps += 1\n",
    "                a = self.explore_or_exploit_policy(state)\n",
    "                s_, reward, done, _ = self.env.step(a)\n",
    "                \n",
    "                # add experience from explore-exploit policy to memory\n",
    "                self.memory.add(state, a, reward, s_, done)\n",
    "                \n",
    "                # update the model every 'update_steps' of experience\n",
    "                if self.steps % self.update_steps == 0:\n",
    "                    self.update_batch()\n",
    "                \n",
    "                # update the target network (if the target network is being used) every 'model_replace_freq' of experiences\n",
    "                if self.steps % self.model_replace_freq == 0:\n",
    "                    self.target_model.replace(self.eval_model)\n",
    "                \n",
    "                state = s_\n",
    "                \n",
    "    def evaluate(self, i, trials = 30):\n",
    "        total_reward = 0\n",
    "        for _ in tqdm(range(trials), desc=\"Evaluating\"):\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            steps = 0\n",
    "\n",
    "            while steps < self.max_episode_steps and not done:\n",
    "                steps += 1\n",
    "                action = self.greedy_policy(state)\n",
    "                state, reward, done, _ = self.env.step(action)\n",
    "                total_reward += reward\n",
    "\n",
    "        avg_reward = total_reward / trials\n",
    "        print(i, \" avg_reward:\", avg_reward)\n",
    "        f = open(result_file, \"a+\")\n",
    "        f.write(str(avg_reward) + \"\\n\")\n",
    "        f.close()\n",
    "        if avg_reward >= self.best_reward:\n",
    "            self.best_reward = avg_reward\n",
    "            self.save_model()\n",
    "        return avg_reward\n",
    "\n",
    "    # save model\n",
    "    def save_model(self):\n",
    "        self.eval_model.save(result_floder + '/best_model.pt')\n",
    "        \n",
    "    # load model\n",
    "    def load_model(self):\n",
    "        self.eval_model.load(result_floder + '/best_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:33<00:00,  1.50it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:07<00:00,  4.35it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  avg_reward: 9.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:35<00:00,  1.50it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:03<00:00,  9.30it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  avg_reward: 9.466666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:36<00:00,  1.38it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 611.28it/s]\n",
      "Training:  36%|███▌      | 18/50 [00:00<00:00, 175.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  avg_reward: 9.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 173.59it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 611.50it/s]\n",
      "Training:  44%|████▍     | 22/50 [00:00<00:00, 207.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  avg_reward: 9.266666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 201.86it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 609.59it/s]\n",
      "Training:  42%|████▏     | 21/50 [00:00<00:00, 204.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  avg_reward: 9.466666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 228.00it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 467.13it/s]\n",
      "Training:  40%|████      | 20/50 [00:00<00:00, 189.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5  avg_reward: 12.266666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 198.72it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 558.87it/s]\n",
      "Training:  44%|████▍     | 22/50 [00:00<00:00, 218.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6  avg_reward: 10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 170.58it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 332.24it/s]\n",
      "Training:  42%|████▏     | 21/50 [00:00<00:00, 203.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  avg_reward: 17.366666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 187.54it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 426.23it/s]\n",
      "Training:  40%|████      | 20/50 [00:00<00:00, 197.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  avg_reward: 15.266666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 165.69it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 234.76it/s]\n",
      "Training:  34%|███▍      | 17/50 [00:00<00:00, 162.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9  avg_reward: 23.966666666666665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 171.86it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 100.15it/s]\n",
      "Training:  34%|███▍      | 17/50 [00:00<00:00, 150.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  avg_reward: 66.13333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 147.71it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 140.25it/s]\n",
      "Training:  24%|██▍       | 12/50 [00:00<00:00, 109.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  avg_reward: 42.86666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 105.78it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 51.82it/s]\n",
      "Training:  32%|███▏      | 16/50 [00:00<00:00, 148.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  avg_reward: 121.76666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 136.05it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 56.42it/s]\n",
      "Training:  12%|█▏        | 6/50 [00:00<00:00, 55.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  avg_reward: 117.03333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 91.44it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.33it/s]\n",
      "Training:  20%|██        | 10/50 [00:00<00:00, 99.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 107.56it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 71.72it/s]\n",
      "Training:  20%|██        | 10/50 [00:00<00:00, 97.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15  avg_reward: 92.33333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 106.93it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 40.28it/s]\n",
      "Training:  26%|██▌       | 13/50 [00:00<00:00, 115.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16  avg_reward: 167.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 99.17it/s] \n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.89it/s]\n",
      "Training:  12%|█▏        | 6/50 [00:00<00:00, 54.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17  avg_reward: 193.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 75.92it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 44.61it/s]\n",
      "Training:  20%|██        | 10/50 [00:00<00:00, 95.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18  avg_reward: 154.43333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 84.21it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 42.62it/s]\n",
      "Training:  20%|██        | 10/50 [00:00<00:00, 92.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19  avg_reward: 156.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 78.35it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 34.84it/s]\n",
      "Training:  12%|█▏        | 6/50 [00:00<00:00, 57.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20  avg_reward: 191.03333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 72.51it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.10it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21  avg_reward: 198.86666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:01<00:00, 48.49it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 34.33it/s]\n",
      "Training:  10%|█         | 5/50 [00:00<00:00, 48.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22  avg_reward: 194.93333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:00<00:00, 50.25it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.11it/s]\n",
      "Training:   6%|▌         | 3/50 [00:00<00:01, 26.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23  avg_reward: 197.23333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:01<00:00, 44.44it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.28it/s]\n",
      "Training:  12%|█▏        | 6/50 [00:00<00:00, 51.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24  avg_reward: 199.93333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:01<00:00, 35.79it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.34it/s]\n",
      "Training:   8%|▊         | 4/50 [00:00<00:01, 34.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25  avg_reward: 199.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:01<00:00, 31.83it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.36it/s]\n",
      "Training:   8%|▊         | 4/50 [00:00<00:01, 37.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26  avg_reward: 199.83333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 18.91it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.20it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27  avg_reward: 199.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 16.97it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 30.94it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 17.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28  avg_reward: 196.46666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 16.36it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 34.04it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29  avg_reward: 197.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 19.23it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 55.13it/s]\n",
      "Training:   8%|▊         | 4/50 [00:00<00:01, 30.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30  avg_reward: 121.56666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 16.37it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 45.67it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31  avg_reward: 144.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 20.41it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 48.86it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 18.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32  avg_reward: 136.63333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 16.40it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.70it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33  avg_reward: 198.26666666666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 17.96it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 345.97it/s]\n",
      "Training:  16%|█▌        | 8/50 [00:00<00:00, 66.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34  avg_reward: 14.766666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:01<00:00, 31.25it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 513.94it/s]\n",
      "Training:  10%|█         | 5/50 [00:00<00:00, 48.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35  avg_reward: 12.633333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 22.88it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 51.71it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36  avg_reward: 129.33333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:01<00:00, 26.13it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 42.94it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 18.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37  avg_reward: 155.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:01<00:00, 39.86it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 337.59it/s]\n",
      "Training:   6%|▌         | 3/50 [00:00<00:01, 29.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38  avg_reward: 16.833333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 21.35it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 228.03it/s]\n",
      "Training:   8%|▊         | 4/50 [00:00<00:01, 38.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39  avg_reward: 28.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 21.07it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 50.74it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 18.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40  avg_reward: 131.16666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 24.41it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 591.66it/s]\n",
      "Training:  24%|██▍       | 12/50 [00:00<00:00, 118.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41  avg_reward: 10.733333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:01<00:00, 28.84it/s] \n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 48.07it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42  avg_reward: 124.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 18.85it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 40.63it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 15.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43  avg_reward: 162.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 18.15it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 51.55it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44  avg_reward: 100.36666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 16.50it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 41.34it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 17.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45  avg_reward: 125.06666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 17.37it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 63.18it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 16.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46  avg_reward: 95.63333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 16.35it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 51.53it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 15.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47  avg_reward: 125.86666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 16.81it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.86it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48  avg_reward: 196.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 19.13it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 57.40it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49  avg_reward: 116.63333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 21.21it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 59.43it/s]\n",
      "Training:   6%|▌         | 3/50 [00:00<00:02, 22.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50  avg_reward: 110.63333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:02<00:00, 18.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 54.89it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51  avg_reward: 120.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 16.07it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 51.72it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52  avg_reward: 127.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 16.47it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 40.92it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:08,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53  avg_reward: 156.83333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 17.51it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.76it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54  avg_reward: 197.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 16.46it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.87it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55  avg_reward: 191.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.54it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 31.03it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56  avg_reward: 198.56666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.25it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.49it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.65it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.03it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.28it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.24it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.05it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.22it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.12it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.16it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.00it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.08it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.21it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.82it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:04,  9.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.01it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 25.99it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:07,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.72it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.17it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.03it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.44it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.24it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 25.97it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.29it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.58it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.41it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.43it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.53it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.41it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.34it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.58it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.43it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.66it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.39it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.19it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.18it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:07,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.06it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.05it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:07,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.75it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.29it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.85it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.14it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.29it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.33it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.98it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.53it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.04it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.83it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.91it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.81it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.79it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.09it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.30it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.12it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.05it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.82it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:08,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.49it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.26it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.86it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.00it/s]\n",
      "Training:   6%|▌         | 3/50 [00:00<00:02, 17.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.14it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.03it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.83it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.24it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:07,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.81it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.14it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 10.33it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.32it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.93it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.25it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:08,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.33it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.45it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.10it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.18it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.20it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.31it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.27it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.31it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.06it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.72it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.01it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.14it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.27it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.31it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.24it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.74it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.24it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.23it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.02it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.69it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.85it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.54it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.10it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.58it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.85it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 25.98it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 14.15it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.05it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.82it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.47it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.87it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.67it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.16it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.55it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.40it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.82it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 10.16it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.88it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.65it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.15it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 10.63it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 25.95it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:08,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.17it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.59it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.18it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.95it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.04it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.27it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.84it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.14it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.84it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.30it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.96it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.61it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.95it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.01it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.47it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.46it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.42it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.49it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.75it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.43it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.15it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.93it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.32it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.24it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:02, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.80it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.78it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.72it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 25.90it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.46it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.29it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.51it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.14it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.83it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.20it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 10.76it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.52it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.18it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.94it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.35it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.97it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 15.53it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 406.74it/s]\n",
      "Training:   6%|▌         | 3/50 [00:00<00:02, 19.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133  avg_reward: 15.933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.46it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.80it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.06it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.04it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.02it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.59it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.44it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.07it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.22it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.26it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.25it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 27.94it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139  avg_reward: 187.53333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.43it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.34it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.82it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:34<00:00,  1.15s/it]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.23it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.25it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [01:45<00:00,  4.86s/it]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [02:24<00:00,  2.88s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.30it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.41it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.17it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145  avg_reward: 197.73333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.07it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 30.74it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.26it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.90it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 13.72it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.75it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [03:08<00:00,  9.54s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:47<00:00,  2.46it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.01it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 34.76it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.67it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 53.80it/s]\n",
      "Training:   8%|▊         | 4/50 [00:00<00:01, 28.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151  avg_reward: 101.83333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.95it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.37it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.31it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.35it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.02it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.76it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.70it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.88it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.98it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 25.98it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:07,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.22it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.00it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.69it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 28.12it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.80it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.66it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.91it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.61it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.00it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.03it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.66it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.20it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 41.42it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163  avg_reward: 153.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 14.00it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 40.74it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 14.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164  avg_reward: 160.96666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.67it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.06it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:04,  9.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.43it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.84it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.11it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.04it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.50it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.00it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168  avg_reward: 196.96666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.38it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.28it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169  avg_reward: 187.03333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.13it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.89it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.09it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 26.82it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.69it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.51it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.99it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 29.14it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.15it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.52it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.17it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 29.80it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.86it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.36it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.32it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.63it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.97it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.32it/s]\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 11.91it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 25.82it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.65it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.47it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.85it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.21it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.64it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.67it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:06,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.05it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.28it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 15.28it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.39it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184  avg_reward: 198.73333333333332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.58it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.23it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.23it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 25.94it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.82it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.04it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.15it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.96it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:04,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.04it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 31.78it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.85it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.78it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 11.71it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.01it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.35it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.44it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.97it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 29.84it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.76it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.52it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.11it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:01<00:00, 29.81it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 13.14it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.57it/s]\n",
      "Training:   2%|▏         | 1/50 [00:00<00:05,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:04<00:00, 12.38it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 32.52it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:04, 11.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 12.62it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 33.26it/s]\n",
      "Training:   4%|▍         | 2/50 [00:00<00:03, 12.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198  avg_reward: 200.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [00:03<00:00, 13.14it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:00<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199  avg_reward: 200.0\n",
      "\n",
      "Learning Performance:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_episodes, test_interval = 10000, 50\n",
    "agent = DQN_agent(env_CartPole, hyperparams_CartPole)\n",
    "result = agent.learn_and_evaluate(training_episodes, test_interval)\n",
    "plot_result(result, test_interval, [\"batch_update with target_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Part 2: Distributed DQN\n",
    "***\n",
    "\n",
    "Here you will implement a distributed version of the above DQN approach. The distribution approach can be the same as that used for the table-based distribution Q-learning algorithm from homework 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-31 11:40:44,871\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /home/u25824/ray_temp/session_2019-05-31_11-40-44_25190/logs.\n",
      "2019-05-31 11:40:45,061\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:27754 to respond...\n",
      "2019-05-31 11:40:45,223\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:62578 to respond...\n",
      "2019-05-31 11:40:45,227\tINFO services.py:760 -- Starting Redis shard with 0.5 GB max memory.\n",
      "2019-05-31 11:40:45,311\tINFO services.py:1384 -- Starting the Plasma object store with 5.0 GB memory using /dev/shm.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': None,\n",
       " 'redis_address': '10.9.1.47:27754',\n",
       " 'object_store_address': '/home/u25824/ray_temp/session_2019-05-31_11-40-44_25190/sockets/plasma_store',\n",
       " 'webui_url': None,\n",
       " 'raylet_socket_name': '/home/u25824/ray_temp/session_2019-05-31_11-40-44_25190/sockets/raylet'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(include_webui=False, ignore_reinit_error=True, redis_max_memory=500000000, object_store_memory=5000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed DQN agent\n",
    "The idea is to speedup learning by creating actors to collect data and a model_server to update the neural network model.\n",
    "- Collector: There is a simulator inside each collector. Their job is to collect exprience from the simulator, and send them to the memory server. They follow the explore_or_exploit policy, getting greedy action from model server. Also, call update function of model server to update the model.  \n",
    "- Evaluator: There is a simulator inside the evaluator. It is called by the the Model Server, taking eval_model from it, and test its performance.\n",
    "- Model Server: Stores the evalation and target networks. It Takes experiences from Memory Server and updates the Q-network, also replacing target Q-network periodically. It also interfaces to the evaluator periodically. \n",
    "- Memory Server: It is used to store/sample experience relays.\n",
    "\n",
    "An image of this architecture is below. \n",
    "\n",
    "For this part, you should use our custom_cartpole as your enviroment. This version of cartpole is slower, which allows for the benefits of distributed experience collection to be observed. In particular, the time to generate an experience tuple needs to be non-trivial compared to the time needed to do a neural network model update. \n",
    "\n",
    "<span style=\"color:green\">It is better to run the distributed DQN agent in exclusive node, not in Jupyter notebook</span>\n",
    "```\n",
    "Store all of your distrited DQN code into a python file.\n",
    "ssh colfax (get access to the Devcloud on terminal)\n",
    "qsub -I -lselect=1\n",
    "python3 distributed_dqn.py\n",
    "```\n",
    "\n",
    "<img src=\"distributed DQN.png\">\n",
    "\n",
    "For this part of the homework you need to submit your code for distributed DQN and run experiments that vary the number of workers involved. Produce some learning curves and timing results and discuss your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_remote import ReplayBuffer_remote\n",
    "from dqn_model import _DQNModel\n",
    "import torch\n",
    "from custom_cartpole import CartPoleEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel, 2019 update 2)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_2019u2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
